{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 4-5-6-7-8-9-10-11: Uncertainty quantification for measurement errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dolfin  # https://fenicsproject.org\n",
    "import logging; logging.getLogger('FFC').setLevel(logging.WARNING)\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import dolfin_mech as dmech\n",
    "\n",
    "import compute_disp\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### default parameter values \n",
    "alpha_healthy = 0.09 ### reference stiffnesses in kPa\n",
    "gamma = 0.5 ### [-]\n",
    "c1, c2 = 0.2, 0.4 ### in kPa\n",
    "pe, pi = -0.5, -2 ### end-exhalation and end-inhalation pleural pressures, in kPa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### uncomment the right parametrization\n",
    "## Figure 4\n",
    "parameters_to_identify = {\"alpha\": 0.09}\n",
    "\n",
    "# ## Figure 5\n",
    "# parameters_to_identify = {\"pi\": -2}\n",
    "\n",
    "# ## Figure 6 - top row\n",
    "# parameters_to_identify = {\"alpha_healthy\": 0.09, \"pi\": -2}\n",
    "\n",
    "## Figure  7 - top row\n",
    "# parameters_to_identify = {\"alpha_healthy\": 0.09, \"alpha_fibrose\": 0.9}\n",
    "\n",
    "# ## Figure  8 - top row\n",
    "# parameters_to_identify = {\"alpha_fibrose\": 0.9, \"pi\": -2}\n",
    "\n",
    "# ## Figure  9 - top row\n",
    "# parameters_to_identify = {\"alpha_fibrose_1\": 0.9, \"alpha_fibrose_2\": 0.67, \"pi\": -2}\n",
    "\n",
    "# ## Figure 10 / 12 - top row \n",
    "# parameters_to_identify = {\"alpha_fibrose_1\": 1.1, \"alpha_fibrose_2\": 0.9, \"alpha_fibrose_3\": 0.67, \"pi\": -2}\n",
    "\n",
    "# ## Figure 11 - top row \n",
    "# parameters_to_identify = {\"alpha_healthy\": 0.09, \"alpha_fibrose\": 0.67, \"pi\": -2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_lst = [0., 0.05, 0.1, 0.2, 0.4] ### noise added to the synthetic data\n",
    "SNR_lst = [(2/noise_lst[i+1] if noise_lst[i] == 0 else 1/noise_lst[i]) for i in range(len(noise_lst))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generic mesh is stored in Data folder - note that the geometry used for the computation is different from the one used for generating the Figures, for copyrights reasons (the authors do not detain ownership of the geometry of the lungs)\n",
    "cube_params = {\"path_and_mesh_name\": \"./Data/mesh_cube.xdmf\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### position for the computations\n",
    "position_lst = [\"Supine\", \"Prone\", \"Supine+Prone\"] ### supine, prone, prone + supine\n",
    "### unloading problem\n",
    "### generic unloading problem, no gravity is applied\n",
    "load_params_unloading_generic = {\"type\":\"p_boundary_condition0\", \"f\":0, \"P0\" : float(pe)} \n",
    "\n",
    "### loading problem\n",
    "### generic end-exhalation configuration in prone and in supine positions\n",
    "load_params_loading_prone = {\"type\":\"p_boundary_condition\", \"f\": -9.81e3, \"P0\" : float(pe)}\n",
    "load_params_loading_supine = {\"type\":\"p_boundary_condition\", \"f\": 9.81e3, \"P0\" : float(pe)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: write reference end-exhalation configurations -prone and supine-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create necessary directories for computations\n",
    "current_directory = os.getcwd() ### get name of current directory\n",
    "directory_prone, directory_supine = helpers.initialize_directories(current_directory) ### if needed, create directories for computations; get name of directories for prone and supine computations\n",
    "\n",
    "### creating mesh for end-exhalation prone and supine\n",
    "mesh_prone = dolfin.Mesh()\n",
    "mesh_supine = dolfin.Mesh()\n",
    "mesh_name = str(cube_params[\"path_and_mesh_name\"])\n",
    "dolfin.XDMFFile(mesh_name).read(mesh_prone)\n",
    "dolfin.XDMFFile(mesh_name).read(mesh_supine)\n",
    "\n",
    "### generic configurations, computed with one zone for the sake of simplicity\n",
    "parameters = {\"alpha\": alpha_healthy, \"gamma\":gamma, \"c1\":c1, \"c2\":c2, \"kappa\":1e2, \"eta\":1e-5}\n",
    "mat_params={\"scaling\": \"linear\", \"parameters\": parameters}\n",
    "\n",
    "### computing unloaded configuration from initial configuration\n",
    "U_unloading, phis_unloading, dV_unloading = dmech.run_RivlinCube_PoroHyperelasticity(\n",
    "    dim = 3,\n",
    "    inverse = 1,\n",
    "    cube_params = cube_params,\n",
    "    porosity_params = {\"type\": \"mesh_function_random_xml\"},\n",
    "    get_results = 1,\n",
    "    mat_params = mat_params,\n",
    "    step_params = {\"dt_min\":1e-4},\n",
    "    load_params = load_params_unloading_generic,\n",
    "    res_basename = \"generic_unloaded\",\n",
    "    inertia_params = {\"applied\":True},\n",
    "    plot_curves = 0,\n",
    "    verbose =1 )\n",
    "\n",
    "#### redefining porosity field in the unloaded configuration so it is physiological\n",
    "phisref_imposed = list(numpy.random.uniform(low = 0.4, high = 0.6, size = len(phis_unloading)))\n",
    "\n",
    "#### computing end-exhalation configuration prone position\n",
    "Uprone, phisprone, dVprone = dmech.run_RivlinCube_PoroHyperelasticity(\n",
    "    dim = 3,\n",
    "    inverse = 0,\n",
    "    porosity_params = {\"type\":\"function_xml_from_array\", \"val\":phisref_imposed},\n",
    "    cube_params = cube_params,\n",
    "    mat_params = mat_params,\n",
    "    step_params = {\"dt_ini\": 0.125, \"dt_min\": 1e-4},\n",
    "    load_params = load_params_loading_prone,\n",
    "    res_basename = directory_prone+\"/prone\",\n",
    "    move_params = {\"move\": True, \"U\": U_unloading},  ### applying the displacement field from generic end-exhalation configuration to unloaded configuration\n",
    "    inertia_params={\"applied\": True},\n",
    "    get_results = 1,\n",
    "    plot_curves=0,\n",
    "    verbose=1)\n",
    "\n",
    "helpers.write_porosity(porosity_field = phisprone, n_cells = len(mesh_prone.cells()), filepath = directory_prone + \"/prone-poro.xml\")\n",
    "\n",
    "### getting displacement field from generic end-exhalation to prone end-exhalation configuration\n",
    "Uexhal_prone = U_unloading.copy(deepcopy=True)\n",
    "Uexhal_prone.vector()[:] +=  Uprone.vector()[:]\n",
    "dolfin.ALE.move(mesh_prone, Uexhal_prone)\n",
    "\n",
    "### writing mesh prone\n",
    "xdmf_file_mesh = dolfin.XDMFFile(directory_prone + \"/cubeprone.xdmf\")\n",
    "xdmf_file_mesh.write(mesh_prone)\n",
    "xdmf_file_mesh.close()\n",
    "\n",
    "#### computing end-exhalation configuration supine position\n",
    "Usupine, phissupine, dVsupine = dmech.run_RivlinCube_PoroHyperelasticity(\n",
    "    dim = 3,\n",
    "    inverse = 0,\n",
    "    porosity_params = {\"type\":\"function_xml_from_array\", \"val\":phisref_imposed},\n",
    "    cube_params = cube_params,\n",
    "    mat_params = mat_params,\n",
    "    step_params = {\"dt_ini\": 0.125, \"dt_min\": 1e-4},\n",
    "    load_params = load_params_loading_supine,\n",
    "    res_basename = directory_supine+\"/supine\",\n",
    "    move_params = {\"move\": True, \"U\": U_unloading},  ### applying the displacement field from generic end-exhalation configuration to unloaded configuration\n",
    "    inertia_params={\"applied\": True},\n",
    "    get_results = 1,\n",
    "    plot_curves=0,\n",
    "    verbose=1)\n",
    "\n",
    "helpers.write_porosity(porosity_field = phissupine, n_cells = len(mesh_supine.cells()), filepath = directory_supine + \"/supine-poro.xml\")\n",
    "\n",
    "### getting displacement field from generic end-exhalation to prone end-exhalation configuration\n",
    "Uexhal_supine = U_unloading.copy(deepcopy=True)\n",
    "Uexhal_supine.vector()[:] +=  Usupine.vector()[:]\n",
    "dolfin.ALE.move(mesh_supine, Uexhal_supine)\n",
    "\n",
    "### writing mesh supine\n",
    "xdmf_file_mesh = dolfin.XDMFFile(directory_supine + \"/cubesupine.xdmf\")\n",
    "xdmf_file_mesh.write(mesh_supine)\n",
    "xdmf_file_mesh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the error distribution of the estimated parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### launching minimizations in parallel for the estimation\n",
    "results_all_positions = {}\n",
    "for position in position_lst:\n",
    "    distribution_converged = ['no'] * len(noise_lst) ### is the distribution converged for each noise level?\n",
    "    results, storing_values_for_convergence_check, storing_processes, reference_value, param_names, nb_parameters = helpers.initialize_lsts_and_params(parameters_to_identify, noise_lst, \"noise\")\n",
    "    ########### computation of reference displacement field\n",
    "    if position=='Supine+Prone':\n",
    "        ### computing displacement field in supine position\n",
    "        Umeas_supine, Vmeas_supine = compute_disp.compute_disp(position = 'Supine', parameters_to_identify = parameters_to_identify, noise='', dirpath = current_directory)\n",
    "        V0_supine = dolfin.assemble(dolfin.Constant(1)*Vmeas_supine)\n",
    "        Umeas_norm_supine = (dolfin.assemble(dolfin.inner(Umeas_supine, Umeas_supine)*Vmeas_supine)/2/V0_supine)**(1/2)\n",
    "        ### writing displacement field supine position\n",
    "        file_supine = dolfin.File(\"refSupine/displacement_exhal_to_inhal.xml\")\n",
    "        file_supine << Umeas_supine\n",
    "        ### computing displacement field in prone position\n",
    "        Umeas_prone, Vmeas_prone = compute_disp.compute_disp(position = 'Prone', parameters_to_identify = parameters_to_identify, noise='', dirpath = current_directory)\n",
    "        V0_prone = dolfin.assemble(dolfin.Constant(1)*Vmeas_prone)\n",
    "        Umeas_norm_prone = (dolfin.assemble(dolfin.inner(Umeas_prone, Umeas_prone)*Vmeas_prone)/2/V0_prone)**(1/2)\n",
    "        ### writing displacement field prone position\n",
    "        file_prone = dolfin.File(\"refProne/displacement_exhal_to_inhal.xml\")\n",
    "        file_prone << Umeas_prone\n",
    "    else :\n",
    "        Umeas, Vmeas = compute_disp.compute_disp(position = position, parameters_to_identify = parameters_to_identify, noise = '', dirpath = current_directory)\n",
    "        V0 = dolfin.assemble(dolfin.Constant(1)*Vmeas)\n",
    "        Umeas_norm = (dolfin.assemble(dolfin.inner(Umeas, Umeas)*Vmeas)/2/V0)**(1/2)\n",
    "        ### writing displacement field in prone or supine (depending on the case investigated) position\n",
    "        file_prone_or_supine = dolfin.File(\"ref\"+str(position)+\"/displacement_exhal_to_inhal.xml\")\n",
    "        file_prone_or_supine << Umeas\n",
    "    ### checking how many CPUs are available to start computations\n",
    "    number_cpus = multiprocessing.cpu_count()\n",
    "    min_iterations = number_cpus // len(noise_lst) ### attribute the same number of CPU for each noise level\n",
    "    converged = False ### convergence of the error distributions - checks if the calculation is over for all noise levels\n",
    "    converged_for_noise_level = False ### variable checking if error distribution converged for a given noise level\n",
    "    while not converged:\n",
    "        converged = all(convergence_status == \"converged\" for convergence_status in distribution_converged) ### checks if the calculation is over for all noise levels\n",
    "        if converged: ### if converged for all noise levels\n",
    "            break\n",
    "        over = False ### variable used to check if all computations launched in parallel are over for a given noise level\n",
    "        for i in range(len(noise_lst)):\n",
    "            if distribution_converged[i] == 'converged': ### if error distribution converged for a given noise level\n",
    "                storing_processes.pop(str(noise_lst[i]), None) ### no more calculation is launched for this noise level\n",
    "            elif distribution_converged[i] == 'no': ### if finished but did not converge\n",
    "                storing_processes[str(noise_lst[i])] = [] ### should launch new computations\n",
    "        for noise, lst in storing_values_for_convergence_check.items(): ### should launch new computations \n",
    "            if distribution_converged[noise_lst.index(float(noise))] == 'no': ### all computations finished for a particular noise level but did not converge, should launch new computations \n",
    "                for iteration in range(0, min_iterations): ### relaunching all processes for a given noise level\n",
    "                    ini_calculation = []\n",
    "                    for param, param_value in parameters_to_identify.items(): ### initializing the computation between -30 and + 30% of the ground-truth value of the parameters\n",
    "                        ini_calculation.append(float(numpy.random.normal(loc = param_value, scale = abs(0.3*param_value), size = 1)[0]))\n",
    "                    process = subprocess.Popen([\"python\",  \"-W\", \"%s\" %\"ignore\", \"./minimization.py\", \"--position\", \"%s\" %position, \"--noise_level\", \"%s\" %noise, \"--parameters_to_identify\", \"%s\" %parameters_to_identify, \"--iteration\", \"%s\" %iteration, \"--dirpath\", \"%s\" %current_directory, \"--initialization\", \"%s\" %ini_calculation], stdout=subprocess.PIPE )  ### launching computation in parallel\n",
    "                    storing_processes[str(noise)].append(process) ### storing each process launched\n",
    "                    distribution_converged[noise_lst.index(float(noise))] = 'waiting' ### changing status from 'no', i.e., finished but not converged, to 'waiting', i.e., no action is done until all processes reach their end (for a given noise level) \n",
    "        while not over: ### while all processes of a given noise level did not finish\n",
    "            time.sleep(1) ### wait before checking again\n",
    "            for noise, lst in storing_processes.items():\n",
    "                noise = float(noise)\n",
    "                over = helpers.checking_if_processes_converged(storing_processes[str(noise)]) ### check if all processes of a given noise finished\n",
    "                if over: ### if all processes ended for a given noise level\n",
    "                    for process in storing_processes[str(noise)]: ### for each process launched\n",
    "                        try: ### read the output of the minimization\n",
    "                            out = process.communicate()[0]\n",
    "                            out = out.decode(\"utf-8\").split()\n",
    "                        except: ### if minimization unsuccessful (e.g., if did not converge fast enough -max number of iteration specified to avoid computations that are too expensive)\n",
    "                            pass       \n",
    "                        process.terminate()  ### ensuring process ends          \n",
    "                        solution = {} ### storing results \n",
    "                        if out != []: ### out is [] if the minimization did not converge\n",
    "                            results['noise'].append(noise) ### storing the results\n",
    "                            for i in range(0, nb_parameters): ### getting the initial values, and the error (in %) of the initialization\n",
    "                                lst_name = \"ini_\"+str(param_names[i])\n",
    "                                results[lst_name].append(((float(out[i])-reference_value[i]))/reference_value[i]*100)\n",
    "                            for k in range (nb_parameters, 2*nb_parameters): ### getting the estimated values, and computing the error (in %)\n",
    "                                i = k - nb_parameters\n",
    "                                results[param_names[i]].append((float(out[k]) - reference_value[i])/reference_value[i]*100)\n",
    "                                storing_values_for_convergence_check[str(noise)][i].append(float(out[k])) ### storing values to check if the error distribution converged\n",
    "                    if len(storing_values_for_convergence_check[str(noise)][0]) > min_iterations+1: ###  minimum number of iterations to check for convergence\n",
    "                        converged_for_noise_level, crit = helpers.checking_if_converged(storing_values_for_convergence_check[str(noise)], len(storing_processes[str(noise)]), tol=5e-2)\n",
    "                    if converged_for_noise_level: ### if the distribution converged\n",
    "                        distribution_converged[noise_lst.index(float(noise))] = 'converged' ### no more minimizations launched for this noise level\n",
    "                    else:\n",
    "                        distribution_converged[noise_lst.index(float(noise))] = 'no' ### new processes will be launched\n",
    "                    break\n",
    "    results_all_positions[position] = results ### dictionary storing results for all positions\n",
    "    df = pd.DataFrame(results)\n",
    "    df_sorted = df.sort_values(by=\"noise\") ### sorting by noise\n",
    "    myfile= open(\"./results_estimation-model_error-position=\"+str(position), 'w') ### sorting by noise\n",
    "    myfile.write(df_sorted.to_string(index=False)) ### writing the error for each position\n",
    "    myfile.close()\n",
    "\n",
    "##### plotting results\n",
    "for parameter_name, value in parameters_to_identify.items():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.cla()\n",
    "    ### plotting parameters\n",
    "    plt.rc(\"xtick\", labelsize=18)\n",
    "    plt.rc(\"ytick\", labelsize=18)\n",
    "    plt.rc(\"legend\", fontsize=16)\n",
    "    plt.ylim([-100, 100])\n",
    "    plt.xlabel(\"Signal to Noise Ratio (SNR)\", fontsize=14)\n",
    "    plt.ylabel(\"Estimation error (%)\", fontsize=14)\n",
    "    color_lst=['royalblue', 'firebrick', 'forestgreen'] ### different color for each position\n",
    "    color_lst_lines=['royalblue', 'firebrick', 'darkgreen']\n",
    "    alpha_lst=[0.6, 0.45, 0.6] ### transparenciesto be able to see all distributions superimposed\n",
    "    label_lst = position_lst.copy()\n",
    "    for position in position_lst:\n",
    "        ### reorganize data \n",
    "        results_position = results_all_positions[position]\n",
    "        frame = pd.DataFrame(results_position)\n",
    "        sorted_frame = frame.sort_values(by=\"noise\")\n",
    "        parametrization_name = ''\n",
    "        stats_results = sorted_frame.groupby(\"noise\")[str(parameter_name)].agg(['mean', 'std'])\n",
    "        stats_results['mean_'+str(parameter_name)] = stats_results['mean']\n",
    "        stats_results['mean_plus_std'+str(parameter_name)] = stats_results['mean'] + stats_results['std']\n",
    "        stats_results['mean_minus_std'+str(parameter_name)] = stats_results['mean'] - stats_results['std']\n",
    "        parametrization_name += parameter_name\n",
    "        #### plot data\n",
    "        plt.plot(SNR_lst, stats_results['mean_'+str(parameter_name)], color=color_lst_lines[0], label = label_lst[0])\n",
    "        ax.fill_between(SNR_lst, stats_results['mean_minus_std'+str(parameter_name)], stats_results['mean_plus_std'+str(parameter_name)], alpha = alpha_lst[0], color = color_lst[0])\n",
    "        color_lst = color_lst[1:]\n",
    "        label_lst = label_lst[1:]\n",
    "        alpha_lst = alpha_lst[1:]\n",
    "        color_lst_lines = color_lst_lines[1:]\n",
    "    plt.xlim([2.5, 44])\n",
    "    plt.gca().set_xscale('log')\n",
    "    ax.errorbar(SNR_lst, len(SNR_lst)*[0], yerr = 30, linewidth = 1, markersize = 10, color = 'black', fmt = 'x', capsize = 5, label = \"Initial distribution\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"parametrization=\"+parametrization_name+\"_identification_parameter=\"+str(parameter_name)+\"_position=\"+str(position)+\"_impact_measurement_errors.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7270dbcea11da5cec531e1718dcee1b0bd6d50ade99199989795797a9208c905"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
